<!DOCTYPE html><!--LLNG8A1tvgYkf40aFD_ma--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/0484562807a97172-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/8888a3826f4a3af4-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/eafabf029ad39a43-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/a60dd70027cfe1b8.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/9738dfd5a8ab60ee.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/c334275b0572c852.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/7a771771047dbf5e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-9692657a345ab50a.js"/><script src="/_next/static/chunks/4bd1b696-409494caf8c83275.js" async=""></script><script src="/_next/static/chunks/255-8db1c35057a14be6.js" async=""></script><script src="/_next/static/chunks/main-app-4ffd0bfd209b03a4.js" async=""></script><script src="/_next/static/chunks/279-82265ca45720155b.js" async=""></script><script src="/_next/static/chunks/619-a625599446862c96.js" async=""></script><script src="/_next/static/chunks/app/layout-5dd220bdd866762c.js" async=""></script><script src="/_next/static/chunks/159-6a7d7131ac72839c.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bslug%5D/page-e8a8016ed60be647.js" async=""></script><meta name="next-size-adjust" content=""/><title>Analyze your users&#x27; sentiment without sending their data to third-party servers | Tanaos Blog</title><meta name="keywords" content="task-specific LLM,offline NLP,text classification,local sentiment analysis,sentiment classification,privacy-first ML"/><link rel="canonical" href="undefined/blog/analyze-user-sentiment-locally/"/><meta property="og:title" content="Analyze your users&#x27; sentiment without sending their data to third-party servers"/><meta property="og:url" content="undefined/blog/analyze-user-sentiment-locally/"/><meta property="og:image" content="https://tanaos.com/images/blog/sentiment-analysis.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Analyze your users&#x27; sentiment without sending their data to third-party servers"/><meta property="og:type" content="article"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Analyze your users&#x27; sentiment without sending their data to third-party servers"/><meta name="twitter:image" content="https://tanaos.com/images/blog/sentiment-analysis.png"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_cc80f9"><div hidden=""><!--$--><!--/$--></div><div class="app"><div class="row Navbar_navbar__3CvTR m-0 false"><div class="m-0 p-0 Navbar_navbar-large-devices__rsA5K"><div class="col m-0 p-0 text-start"><img alt="Create task-specific LLMs for NLP and Text Classification | Tanaos" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" class="Navbar_logo__RSROF" style="color:transparent" src="/images/logo.png"/></div><div class="col m-0 p-0 text-end"><div class="Navigation_navigation__Eln2g"><a href="https://platform.tanaos.com" rel="noreferrer" target="_blank" class="mt-4 mt-md-0 ms-md-4">Platform</a><a class="btn btn-white mt-4 mt-md-0 ms-md-4" href="#try-it-out">Create your model <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="1em" height="1em" fill="currentColor" class="bi bi-arrow-right ms-1"><path fill-rule="evenodd" d="M1 8a.5.5 0 0 1 .5-.5h11.793l-3.147-3.146a.5.5 0 0 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 0 1-.708-.708L13.293 8.5H1.5A.5.5 0 0 1 1 8"></path></svg></a></div></div></div><div class="Navbar_navbar-small-devices__w8Bl9 d-md-none m-0 p-0 d-flex align-items-center"><div class="col-10 m-0 p-0 text-start"><img alt="Create task-specific LLMs for NLP and Text Classification | Tanaos" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" class="Navbar_logo__RSROF" style="color:transparent" src="/images/logo.png"/></div><div class="col-2 m-0 p-0 text-end"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="1em" height="1em" fill="currentColor" class="bi bi-list Navbar_navbar-toggle-icon__TXjJe"><path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5m0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5m0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5"></path></svg></div></div><div class="d-md-none Navbar_navbar-collapse__09PzW text-start false"><div class="mt-4"><div class="Navigation_navigation__Eln2g"><a href="https://platform.tanaos.com" rel="noreferrer" target="_blank" class="mt-4 mt-md-0 ms-md-4">Platform</a><a class="btn btn-white mt-4 mt-md-0 ms-md-4" href="#try-it-out">Create your model <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="1em" height="1em" fill="currentColor" class="bi bi-arrow-right ms-1"><path fill-rule="evenodd" d="M1 8a.5.5 0 0 1 .5-.5h11.793l-3.147-3.146a.5.5 0 0 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 0 1-.708-.708L13.293 8.5H1.5A.5.5 0 0 1 1 8"></path></svg></a></div></div></div></div><main class="content"><article class="BlogPage_article__fv9gc"><a class="BlogPage_back-link__G6xqk" href="/blog/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="1em" height="1em" fill="currentColor" class="bi bi-arrow-left"><path fill-rule="evenodd" d="M15 8a.5.5 0 0 0-.5-.5H2.707l3.147-3.146a.5.5 0 1 0-.708-.708l-4 4a.5.5 0 0 0 0 .708l4 4a.5.5 0 0 0 .708-.708L2.707 8.5H14.5A.5.5 0 0 0 15 8"></path></svg> Back to blog</a><h1 class="mt-4">Analyze your users&#x27; sentiment without sending their data to third-party servers</h1><p class="BlogPage_subtitle__wqaGw">Perform local sentiment analysis using a small, task-specific LLM that runs entirely on your CPU without making it go BRRR.</p><p class="BlogPage_date__VyN7U">December 16, 2025</p><img alt="Analyze your users&#x27; sentiment without sending their data to third-party servers" loading="lazy" width="1200" height="630" decoding="async" data-nimg="1" class="mt-5 mb-5 BlogPage_post-image__Du0zR" style="color:transparent" src="/images/blog/sentiment-analysis.png"/><p>As we noted in our previous <a href="/blog/offline-nlp/">post on offline NLP</a>,
many developers have gotten used to throwing an LLM API, or at least a general-purpose LLM, at
whatever language-related problem they are facing. While this is probably the most practical choice,
or at least the one that comes to mind most easily, it is not necessarily to best one in terms
of <strong>costs, data privacy and speed</strong>.</p>
<p>Let&#x27;s see why.</p>
<h2>Our objective</h2>
<p>Let&#x27;s say we have a tech product that&#x27;s been on the market for a few months. Our social media pages
are quite active, and we get lots of user feedback.</p>
<p>As it turns out, most users love our product, some users find it <em>meh</em> and a handful of them
hate it. Or at least that&#x27;s what our gut feeling is, based on comments to our social media posts
and direct messages we receive. If we want to have a more precise idea of what users think, however,
<strong>we need metrics</strong>.</p>
<h2>The classic approach</h2>
<p>That&#x27;s easy enough. We will just find a way to download all user comments and DMs, put them in a
CSV file and feed it to the OpenAI API.</p>
<p>The CSV file might look something like this.</p>
<div class="CodeSnippet_code-snippet-container__pp8Le mb-5"><pre class="code-block" style="background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1rem;margin:0;overflow:auto;border-radius:0.75rem"><code class="language-csv" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">time</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">username</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">comment</span><span>
</span><span></span><span class="token">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">2025-12-01 12:34:56</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">user1234</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">&quot;I love this product! It has changed my life.&quot;</span><span>
</span><span></span><span class="token">2</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">2025-12-02 14:23:45</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">user5678</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">&quot;This product is okay, but it could be better.&quot;</span><span>
</span><span></span><span class="token">3</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">2025-12-03 16:12:34</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">user9101</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">&quot;I hate it! It&#x27;s the worst thing I&#x27;ve ever used.&quot;</span><span>
</span><span></span><span class="token">...</span><span>
</span><span></span><span class="token">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">2025-12-15 18:45:23</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">user4321</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">&quot;Not bad, but not great either.&quot;</span><span>
</span></code></pre><button class=""><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="1em" height="1em" fill="currentColor" class="bi bi-clipboard"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1z"></path><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0z"></path></svg></button></div>
<p><em>Classic user9101. Always so dramatic.</em></p>
<p>Now let&#x27;s write a simple script that reads the CSV file, sends each comment to the OpenAI API
for sentiment analysis, and stores the results in a new CSV file.</p>
<div class="CodeSnippet_code-snippet-container__pp8Le mb-5"><pre class="code-block" style="background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1rem;margin:0;overflow:auto;border-radius:0.75rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> csv
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> OpenAI
</span>
<!-- -->
<span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;YOUR_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">analyze_sentiment</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>comment</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>  prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Analyze the sentiment of the following comment: &#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">comment</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&#x27;. Return a single word: &#x27;very_positive&#x27;, &#x27;positive&#x27;, &#x27;neutral&#x27;, &#x27;negative&#x27; or &#x27;very_negative&#x27;.&quot;</span><span>
</span>
<span>  response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>      model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4.1&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>      messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>          </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a sentiment analysis assistant.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>          </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>      </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>  </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>  sentiment </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>strip</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>  </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> sentiment
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_comments.csv&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> mode</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;r&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> newline</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> encoding</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;utf-8&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> infile</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_comments_with_sentiment.csv&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> mode</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;w&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> newline</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> encoding</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;utf-8&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> outfile</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>  reader </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> csv</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DictReader</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>infile</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>  fieldnames </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> reader</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fieldnames </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;sentiment&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>  writer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> csv</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DictWriter</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>outfile</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> fieldnames</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>fieldnames</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>  writer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>writeheader</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>  </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> row </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> reader</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>      comment </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;comment&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>      sentiment </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> analyze_sentiment</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>comment</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>      row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;sentiment&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> sentiment
</span><span>      writer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>writerow</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>row</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span></code></pre><button class=""><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="1em" height="1em" fill="currentColor" class="bi bi-clipboard"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1z"></path><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0z"></path></svg></button></div>
<p>The result looks like this.</p>
<div class="CodeSnippet_code-snippet-container__pp8Le mb-5"><pre class="code-block" style="background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1rem;margin:0;overflow:auto;border-radius:0.75rem"><code class="language-csv" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">time</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">username</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">comment</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">sentiment</span><span>
</span><span></span><span class="token">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">2025-12-01 12:34:56</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">user1234</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">&quot;I love this product! It has changed my life.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">very_positive</span><span>
</span><span></span><span class="token">2</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">2025-12-02 14:23:45</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">user5678</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">&quot;This product is okay, but it could be better.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">neutral</span><span>
</span><span></span><span class="token">3</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">2025-12-03 16:12:34</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">user9101</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">&quot;I hate it! It&#x27;s the worst thing I&#x27;ve ever used.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">very_negative</span><span>
</span><span></span><span class="token">...</span><span>
</span><span></span><span class="token">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">2025-12-15 18:45:23</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">user4321</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">&quot;Not bad, but not great either.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">neutral</span><span>
</span></code></pre><button class=""><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="1em" height="1em" fill="currentColor" class="bi bi-clipboard"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1z"></path><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0z"></path></svg></button></div>
<p>The result is what we wanted, the process was relatively fast and, unless our CSV dataset had a billion rows, the
cost was negligible.</p>
<h2>The privacy problem</h2>
<p>If it was so easy, then why did we even bother writing this tutorial? Well, if you think about it, each one of
those reviews was sent to a <strong>third-party server</strong>, together with the <strong>username of the person who wrote it</strong>
and the <strong>timestamp</strong> at which it was written. Even if we wrote the script in such a way that OpenAI API only
receives the actual reviews (and not username and timestamp), chances are that some of the reviews themselves
contain <strong>personally identifiable information</strong> (PII), like names, locations, email addresses, phone numbers,
etc.</p>
<p>Would our users be happy if they found out that, unbeknownst to them, their reviews and messages were sent to
a <strong>third-party server for analysis</strong>? Probably not. Is this <strong>GDPR-compliant</strong>? Certainly not. Could we technically
<strong>face a lawsuit</strong>? I am afraid so.</p>
<h2>A better approach: local sentiment analysis</h2>
<p>We could, in theory, bypass the privacy issue by hosting our own instance of an open-source general-purpose LLM,
like Llama, DeepSeek or Mistral. But do we really want to host a <strong>multi-billion parameter model</strong> on our own servers,
<strong>just to analyze product reviews</strong>? Not really.</p>
<p>The better approach is to use a <strong>small, task-specific model</strong> that can run entirely on our local device, without
sending any data to third-party servers or requiring GPU acceleration. But where do we find a small model that can run
locally? Do we really have to look for one on Hugging Face and read its docs to figure out how to use it? We have
better plans for the weekend.</p>
<p>This is where <a href="https://github.com/tanaos/artifex">Artifex</a> comes in. Artifex is a Python library that
provides easy access to a variety of small, task-specific LLMs that run entirely on your CPU, as well as the
possibility to fine-tune them on your specific tasks. Our sentiment analysis task is standard enough that Artifex
already provides a <strong>pre-trained model</strong> for it, without any need for fine-tuning.</p>
<p>Let&#x27;s see how to do it.</p>
<h3>The new script</h3>
<p>First of all, let&#x27;s install Artifex.</p>
<div class="CodeSnippet_code-snippet-container__pp8Le mb-5"><pre class="code-block" style="background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1rem;margin:0;overflow:auto;border-radius:0.75rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>pip install artifex</span></code></pre><button class=""><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="1em" height="1em" fill="currentColor" class="bi bi-clipboard"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1z"></path><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0z"></path></svg></button></div>
<p>Once that&#x27;s done, let&#x27;s rewrite our previous script using Artifex&#x27;s sentiment analysis model.</p>
<div class="CodeSnippet_code-snippet-container__pp8Le mb-5"><pre class="code-block" style="background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1rem;margin:0;overflow:auto;border-radius:0.75rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> csv
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> artifex </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> Artifex
</span>
<span>sentiment_analyzer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> Artifex</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sentiment_analysis
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_comments.csv&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> mode</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;r&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> newline</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> encoding</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;utf-8&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> infile</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_comments_with_sentiment.csv&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> mode</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;w&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> newline</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> encoding</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;utf-8&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> outfile</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>  reader </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> csv</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DictReader</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>infile</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>  fieldnames </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> reader</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fieldnames </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;sentiment&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>  writer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> csv</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DictWriter</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>outfile</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> fieldnames</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>fieldnames</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>  writer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>writeheader</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>  </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> row </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> reader</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>      comment </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;comment&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>      sentiment </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> sentiment_analyzer</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>comment</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>label
</span><span>      row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;sentiment&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> sentiment
</span><span>      writer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>writerow</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>row</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span></code></pre><button class=""><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="1em" height="1em" fill="currentColor" class="bi bi-clipboard"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1z"></path><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0z"></path></svg></button></div>
<p>What we did here is instantiate an Artifex object and use its <code>sentiment_analysis</code> method to
analyze each comment. We removed the <code>analyze_sentiment</code> function and all references to OpenAI API,
since we don&#x27;t need it anymore. The rest of the script remains unchanged.</p>
<p>If you need more information on how to use Artifex or the sentiment analysis model specifically, please refer
to the <a href="https://docs.tanaos.com/artifex/sentiment-analysis/train/" target="_blank" rel="noreferrer">Artifex documentation</a>.</p>
<p>The new script gives us the same result as before.</p>
<div class="CodeSnippet_code-snippet-container__pp8Le mb-5"><pre class="code-block" style="background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1rem;margin:0;overflow:auto;border-radius:0.75rem"><code class="language-csv" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">time</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">username</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">comment</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">sentiment</span><span>
</span><span></span><span class="token">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">2025-12-01 12:34:56</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">user1234</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">&quot;I love this product! It has changed my life.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">very_positive</span><span>
</span><span></span><span class="token">2</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">2025-12-02 14:23:45</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">user5678</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">&quot;This product is okay, but it could be better.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">neutral</span><span>
</span><span></span><span class="token">3</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">2025-12-03 16:12:34</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">user9101</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">&quot;I hate it! It&#x27;s the worst thing I&#x27;ve ever used.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">very_negative</span><span>
</span><span></span><span class="token">...</span><span>
</span><span></span><span class="token">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">2025-12-15 18:45:23</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">user4321</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">&quot;Not bad, but not great either.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span class="token">neutral</span><span>
</span></code></pre><button class=""><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="1em" height="1em" fill="currentColor" class="bi bi-clipboard"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1z"></path><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0z"></path></svg></button></div>
<p>Cost of running the new script was $0, speed was comparable to the previous version, and most
importantly, our users&#x27; data never leaves our device and we don&#x27;t risk having to hire a lawyer.</p>
<h3>The pre-trained model</h3>
<p>The <code>sentiment_analysis</code> method we used in the script above employs a small, pre-trained language
model that was created with Artifex itself. If you would like to know more about the model
architecture or capapilities, or what the training process looked like, check out
the <a href="https://huggingface.co/tanaos/tanaos-sentiment-analysis-v1" target="_blank" rel="noreferrer">model&#x27;s Hugging Face page</a>.</p>
<h2>Conclusion</h2>
<p>In this post, we saw how to use Artifex to perform local sentiment analysis using a small,
task-specific LLM that runs entirely on our CPU. This approach allows us to analyze user feedback
while preserving their privacy.</p>
<p>Artifex provides many other task-specific models that can be used for various NLP tasks, such as
text classification, named entity recognition, guardrailing, and more. Feel free to explore the
<a href="https://github.com/tanaos/artifex" target="_blank" rel="noreferrer">Artifex GitHub repository</a> and the
<a href="https://docs.tanaos.com/artifex/" target="_blank" rel="noreferrer">Artifex docs</a> for more information.</p></article><!--$--><!--/$--></main><div class="row Footer_footer__Ir1kR m-0 align-items-center"><div class="col-12 col-md-4 m-0 p-0 text-start">Copyright Â© <!-- -->2026<!-- --> Tanaos</div><div class="col-md-4 text-md-center d-none d-md-block">Tanaos</div><div class="col-12 col-md-4 text-md-end mt-4 mt-md-0 Footer_footer-links__9Skqm m-0 p-0"><a href="/">Home</a><a href="/blog/">Blog</a><a href="https://platform.tanaos.com" rel="noreferrer" target="_blank">Platform</a></div></div></div><script src="/_next/static/chunks/webpack-9692657a345ab50a.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[91694,[\"279\",\"static/chunks/279-82265ca45720155b.js\",\"619\",\"static/chunks/619-a625599446862c96.js\",\"177\",\"static/chunks/app/layout-5dd220bdd866762c.js\"],\"Navbar\"]\n3:I[9766,[],\"\"]\n4:I[98924,[],\"\"]\n5:I[52619,[\"279\",\"static/chunks/279-82265ca45720155b.js\",\"619\",\"static/chunks/619-a625599446862c96.js\",\"159\",\"static/chunks/159-6a7d7131ac72839c.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-e8a8016ed60be647.js\"],\"\"]\n6:I[41402,[\"279\",\"static/chunks/279-82265ca45720155b.js\",\"619\",\"static/chunks/619-a625599446862c96.js\",\"177\",\"static/chunks/app/layout-5dd220bdd866762c.js\"],\"\"]\n8:I[24431,[],\"OutletBoundary\"]\na:I[15278,[],\"AsyncMetadataOutlet\"]\nc:I[24431,[],\"ViewportBoundary\"]\ne:I[24431,[],\"MetadataBoundary\"]\nf:\"$Sreact.suspense\"\n11:I[57150,[],\"\"]\n:HL[\"/_next/static/media/0484562807a97172-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/8888a3826f4a3af4-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/eafabf029ad39a43-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/a60dd70027cfe1b8.css\",\"style\"]\n:HL[\"/_next/static/css/9738dfd5a8ab60ee.css\",\"style\"]\n:HL[\"/_next/static/css/c334275b0572c852.css\",\"style\"]\n:HL[\"/_next/static/css/7a771771047dbf5e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"LLNG8A1tvgYkf40aFD-ma\",\"p\":\"\",\"c\":[\"\",\"blog\",\"analyze-user-sentiment-locally\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"analyze-user-sentiment-locally\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/a60dd70027cfe1b8.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/9738dfd5a8ab60ee.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/c334275b0572c852.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_cc80f9\",\"children\":[[\"$\",\"div\",null,{\"className\":\"app\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"main\",null,{\"className\":\"content\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"div\",null,{\"className\":\"row Footer_footer__Ir1kR m-0 align-items-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"col-12 col-md-4 m-0 p-0 text-start\",\"children\":[\"Copyright Â© \",2026,\" Tanaos\"]}],[\"$\",\"div\",null,{\"className\":\"col-md-4 text-md-center d-none d-md-block\",\"children\":\"Tanaos\"}],[\"$\",\"div\",null,{\"className\":\"col-12 col-md-4 text-md-end mt-4 mt-md-0 Footer_footer-links__9Skqm m-0 p-0\",\"children\":[[\"$\",\"$L5\",null,{\"href\":\"/\",\"children\":\"Home\"}],[\"$\",\"$L5\",null,{\"href\":\"/blog/\",\"children\":\"Blog\"}],[\"$\",\"a\",null,{\"href\":\"https://platform.tanaos.com\",\"rel\":\"noreferrer\",\"target\":\"_blank\",\"children\":\"Platform\"}]]}]]}]]}],[\"$\",\"$L6\",null,{\"id\":\"ga-init\",\"strategy\":\"afterInteractive\",\"children\":\"\\n                        window.dataLayer = window.dataLayer || [];\\n                        function gtag(){dataLayer.push(arguments);}\\n                        gtag('js', new Date());\\n                        gtag('config', 'G-HRQ77GT2C8');\\n                    \"}]]}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"analyze-user-sentiment-locally\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L7\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/7a771771047dbf5e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L8\",null,{\"children\":[\"$L9\",[\"$\",\"$La\",null,{\"promise\":\"$@b\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$Le\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$f\",null,{\"fallback\":null,\"children\":\"$L10\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"12:I[81356,[\"279\",\"static/chunks/279-82265ca45720155b.js\",\"619\",\"static/chunks/619-a625599446862c96.js\",\"159\",\"static/chunks/159-6a7d7131ac72839c.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-e8a8016ed60be647.js\"],\"Image\"]\n13:I[50270,[\"279\",\"static/chunks/279-82265ca45720155b.js\",\"619\",\"static/chunks/619-a625599446862c96.js\",\"159\",\"static/chunks/159-6a7d7131ac72839c.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-e8a8016ed60be647.js\"],\"CodeSnippet\"]\n14:T444,"])</script><script>self.__next_f.push([1,"import csv\nfrom openai import OpenAI\n\n\nclient = OpenAI(api_key=\"YOUR_API_KEY\")\n\ndef analyze_sentiment(comment):\n  prompt = f\"Analyze the sentiment of the following comment: '{comment}'. Return a single word: 'very_positive', 'positive', 'neutral', 'negative' or 'very_negative'.\"\n\n  response = client.chat.completions.create(\n      model=\"gpt-4.1\",\n      messages=[\n          {\"role\": \"system\", \"content\": \"You are a sentiment analysis assistant.\"},\n          {\"role\": \"user\", \"content\": prompt}\n      ]\n  )\n  sentiment = response.choices[0].message.content.strip().lower()\n  return sentiment\n\nwith open(\"user_comments.csv\", mode=\"r\", newline=\"\", encoding=\"utf-8\") as infile, open(\"user_comments_with_sentiment.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n  reader = csv.DictReader(infile)\n  fieldnames = reader.fieldnames + [\"sentiment\"]\n  writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n  writer.writeheader()\n  for row in reader:\n      comment = row[\"comment\"]\n      sentiment = analyze_sentiment(comment)\n      row[\"sentiment\"] = sentiment\n      writer.writerow(row)\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"article\",null,{\"className\":\"BlogPage_article__fv9gc\",\"children\":[[\"$\",\"$L5\",null,{\"href\":\"/blog/\",\"className\":\"BlogPage_back-link__G6xqk\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"viewBox\":\"0 0 16 16\",\"width\":\"1em\",\"height\":\"1em\",\"fill\":\"currentColor\",\"className\":\"bi bi-arrow-left\",\"children\":[null,[\"$\",\"path\",null,{\"fillRule\":\"evenodd\",\"d\":\"M15 8a.5.5 0 0 0-.5-.5H2.707l3.147-3.146a.5.5 0 1 0-.708-.708l-4 4a.5.5 0 0 0 0 .708l4 4a.5.5 0 0 0 .708-.708L2.707 8.5H14.5A.5.5 0 0 0 15 8\"}]]}],\" Back to blog\"]}],[\"$\",\"h1\",null,{\"className\":\"mt-4\",\"children\":\"Analyze your users' sentiment without sending their data to third-party servers\"}],[\"$\",\"p\",null,{\"className\":\"BlogPage_subtitle__wqaGw\",\"children\":\"Perform local sentiment analysis using a small, task-specific LLM that runs entirely on your CPU without making it go BRRR.\"}],[\"$\",\"p\",null,{\"className\":\"BlogPage_date__VyN7U\",\"children\":\"December 16, 2025\"}],[\"$\",\"$L12\",null,{\"className\":\"mt-5 mb-5 BlogPage_post-image__Du0zR\",\"src\":\"/images/blog/sentiment-analysis.png\",\"alt\":\"Analyze your users' sentiment without sending their data to third-party servers\",\"width\":1200,\"height\":630,\"unoptimized\":true}],[[\"$\",\"p\",null,{\"children\":[\"As we noted in our previous \",[\"$\",\"$L5\",null,{\"href\":\"/blog/offline-nlp/\",\"children\":\"post on offline NLP\"}],\",\\nmany developers have gotten used to throwing an LLM API, or at least a general-purpose LLM, at\\nwhatever language-related problem they are facing. While this is probably the most practical choice,\\nor at least the one that comes to mind most easily, it is not necessarily to best one in terms\\nof \",[\"$\",\"strong\",null,{\"children\":\"costs, data privacy and speed\"}],\".\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Let's see why.\"}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Our objective\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Let's say we have a tech product that's been on the market for a few months. Our social media pages\\nare quite active, and we get lots of user feedback.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"As it turns out, most users love our product, some users find it \",[\"$\",\"em\",null,{\"children\":\"meh\"}],\" and a handful of them\\nhate it. Or at least that's what our gut feeling is, based on comments to our social media posts\\nand direct messages we receive. If we want to have a more precise idea of what users think, however,\\n\",[\"$\",\"strong\",null,{\"children\":\"we need metrics\"}],\".\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"The classic approach\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"That's easy enough. We will just find a way to download all user comments and DMs, put them in a\\nCSV file and feed it to the OpenAI API.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The CSV file might look something like this.\"}],\"\\n\",[\"$\",\"$L13\",null,{\"language\":\"csv\",\"code\":\"id,time,username,comment\\n1,2025-12-01 12:34:56,user1234,\\\"I love this product! It has changed my life.\\\"\\n2,2025-12-02 14:23:45,user5678,\\\"This product is okay, but it could be better.\\\"\\n3,2025-12-03 16:12:34,user9101,\\\"I hate it! It's the worst thing I've ever used.\\\"\\n...\\n1000,2025-12-15 18:45:23,user4321,\\\"Not bad, but not great either.\\\"\\n\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"em\",null,{\"children\":\"Classic user9101. Always so dramatic.\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Now let's write a simple script that reads the CSV file, sends each comment to the OpenAI API\\nfor sentiment analysis, and stores the results in a new CSV file.\"}],\"\\n\",[\"$\",\"$L13\",null,{\"language\":\"python\",\"code\":\"$14\"}],\"\\n\",\"$L15\",\"\\n\",\"$L16\",\"\\n\",\"$L17\",\"\\n\",\"$L18\",\"\\n\",\"$L19\",\"\\n\",\"$L1a\",\"\\n\",\"$L1b\",\"\\n\",\"$L1c\",\"\\n\",\"$L1d\",\"\\n\",\"$L1e\",\"\\n\",\"$L1f\",\"\\n\",\"$L20\",\"\\n\",\"$L21\",\"\\n\",\"$L22\",\"\\n\",\"$L23\",\"\\n\",\"$L24\",\"\\n\",\"$L25\",\"\\n\",\"$L26\",\"\\n\",\"$L27\",\"\\n\",\"$L28\",\"\\n\",\"$L29\",\"\\n\",\"$L2a\",\"\\n\",\"$L2b\",\"\\n\",\"$L2c\",\"\\n\",\"$L2d\",\"\\n\",\"$L2e\"]]}]\n"])</script><script>self.__next_f.push([1,"15:[\"$\",\"p\",null,{\"children\":\"The result looks like this.\"}]\n16:[\"$\",\"$L13\",null,{\"language\":\"csv\",\"code\":\"id,time,username,comment,sentiment\\n1,2025-12-01 12:34:56,user1234,\\\"I love this product! It has changed my life.\\\",very_positive\\n2,2025-12-02 14:23:45,user5678,\\\"This product is okay, but it could be better.\\\",neutral\\n3,2025-12-03 16:12:34,user9101,\\\"I hate it! It's the worst thing I've ever used.\\\",very_negative\\n...\\n1000,2025-12-15 18:45:23,user4321,\\\"Not bad, but not great either.\\\",neutral\\n\"}]\n17:[\"$\",\"p\",null,{\"children\":\"The result is what we wanted, the process was relatively fast and, unless our CSV dataset had a billion rows, the\\ncost was negligible.\"}]\n18:[\"$\",\"h2\",null,{\"children\":\"The privacy problem\"}]\n"])</script><script>self.__next_f.push([1,"19:[\"$\",\"p\",null,{\"children\":[\"If it was so easy, then why did we even bother writing this tutorial? Well, if you think about it, each one of\\nthose reviews was sent to a \",[\"$\",\"strong\",null,{\"children\":\"third-party server\"}],\", together with the \",[\"$\",\"strong\",null,{\"children\":\"username of the person who wrote it\"}],\"\\nand the \",[\"$\",\"strong\",null,{\"children\":\"timestamp\"}],\" at which it was written. Even if we wrote the script in such a way that OpenAI API only\\nreceives the actual reviews (and not username and timestamp), chances are that some of the reviews themselves\\ncontain \",[\"$\",\"strong\",null,{\"children\":\"personally identifiable information\"}],\" (PII), like names, locations, email addresses, phone numbers,\\netc.\"]}]\n"])</script><script>self.__next_f.push([1,"1a:[\"$\",\"p\",null,{\"children\":[\"Would our users be happy if they found out that, unbeknownst to them, their reviews and messages were sent to\\na \",[\"$\",\"strong\",null,{\"children\":\"third-party server for analysis\"}],\"? Probably not. Is this \",[\"$\",\"strong\",null,{\"children\":\"GDPR-compliant\"}],\"? Certainly not. Could we technically\\n\",[\"$\",\"strong\",null,{\"children\":\"face a lawsuit\"}],\"? I am afraid so.\"]}]\n1b:[\"$\",\"h2\",null,{\"children\":\"A better approach: local sentiment analysis\"}]\n1c:[\"$\",\"p\",null,{\"children\":[\"We could, in theory, bypass the privacy issue by hosting our own instance of an open-source general-purpose LLM,\\nlike Llama, DeepSeek or Mistral. But do we really want to host a \",[\"$\",\"strong\",null,{\"children\":\"multi-billion parameter model\"}],\" on our own servers,\\n\",[\"$\",\"strong\",null,{\"children\":\"just to analyze product reviews\"}],\"? Not really.\"]}]\n1d:[\"$\",\"p\",null,{\"children\":[\"The better approach is to use a \",[\"$\",\"strong\",null,{\"children\":\"small, task-specific model\"}],\" that can run entirely on our local device, without\\nsending any data to third-party servers or requiring GPU acceleration. But where do we find a small model that can run\\nlocally? Do we really have to look for one on Hugging Face and read its docs to figure out how to use it? We have\\nbetter plans for the weekend.\"]}]\n1e:[\"$\",\"p\",null,{\"children\":[\"This is where \",[\"$\",\"$L5\",null,{\"href\":\"https://github.com/tanaos/artifex\",\"children\":\"Artifex\"}],\" comes in. Artifex is a Python library that\\nprovides easy access to a variety of small, task-specific LLMs that run entirely on your CPU, as well as the\\npossibility to fine-tune them on your specific tasks. Our sentiment analysis task is standard enough that Artifex\\nalready provides a \",[\"$\",\"strong\",null,{\"children\":\"pre-trained model\"}],\" for it, without any need for fine-tuning.\"]}]\n1f:[\"$\",\"p\",null,{\"children\":\"Let's see how to do it.\"}]\n20:[\"$\",\"h3\",null,{\"children\":\"The new script\"}]\n21:[\"$\",\"p\",null,{\"children\":\"First of all, let's install Artifex.\"}]\n22:[\"$\",\"$L13\",null,{\"code\":"])</script><script>self.__next_f.push([1,"\"pip install artifex\"}]\n23:[\"$\",\"p\",null,{\"children\":\"Once that's done, let's rewrite our previous script using Artifex's sentiment analysis model.\"}]\n"])</script><script>self.__next_f.push([1,"24:[\"$\",\"$L13\",null,{\"language\":\"python\",\"code\":\"import csv\\nfrom artifex import Artifex\\n\\nsentiment_analyzer = Artifex().sentiment_analysis\\n\\nwith open(\\\"user_comments.csv\\\", mode=\\\"r\\\", newline=\\\"\\\", encoding=\\\"utf-8\\\") as infile, open(\\\"user_comments_with_sentiment.csv\\\", mode=\\\"w\\\", newline=\\\"\\\", encoding=\\\"utf-8\\\") as outfile:\\n  reader = csv.DictReader(infile)\\n  fieldnames = reader.fieldnames + [\\\"sentiment\\\"]\\n  writer = csv.DictWriter(outfile, fieldnames=fieldnames)\\n  writer.writeheader()\\n  for row in reader:\\n      comment = row[\\\"comment\\\"]\\n      sentiment = sentiment_analyzer(comment)[0].label\\n      row[\\\"sentiment\\\"] = sentiment\\n      writer.writerow(row)\\n\"}]\n"])</script><script>self.__next_f.push([1,"25:[\"$\",\"p\",null,{\"children\":[\"What we did here is instantiate an Artifex object and use its \",[\"$\",\"code\",null,{\"children\":\"sentiment_analysis\"}],\" method to\\nanalyze each comment. We removed the \",[\"$\",\"code\",null,{\"children\":\"analyze_sentiment\"}],\" function and all references to OpenAI API,\\nsince we don't need it anymore. The rest of the script remains unchanged.\"]}]\n26:[\"$\",\"p\",null,{\"children\":[\"If you need more information on how to use Artifex or the sentiment analysis model specifically, please refer\\nto the \",[\"$\",\"a\",null,{\"href\":\"https://docs.tanaos.com/artifex/sentiment-analysis/train/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":\"Artifex documentation\"}],\".\"]}]\n27:[\"$\",\"p\",null,{\"children\":\"The new script gives us the same result as before.\"}]\n28:[\"$\",\"$L13\",null,{\"language\":\"csv\",\"code\":\"id,time,username,comment,sentiment\\n1,2025-12-01 12:34:56,user1234,\\\"I love this product! It has changed my life.\\\",very_positive\\n2,2025-12-02 14:23:45,user5678,\\\"This product is okay, but it could be better.\\\",neutral\\n3,2025-12-03 16:12:34,user9101,\\\"I hate it! It's the worst thing I've ever used.\\\",very_negative\\n...\\n1000,2025-12-15 18:45:23,user4321,\\\"Not bad, but not great either.\\\",neutral\\n\"}]\n29:[\"$\",\"p\",null,{\"children\":\"Cost of running the new script was $0, speed was comparable to the previous version, and most\\nimportantly, our users' data never leaves our device and we don't risk having to hire a lawyer.\"}]\n2a:[\"$\",\"h3\",null,{\"children\":\"The pre-trained model\"}]\n2b:[\"$\",\"p\",null,{\"children\":[\"The \",[\"$\",\"code\",null,{\"children\":\"sentiment_analysis\"}],\" method we used in the script above employs a small, pre-trained language\\nmodel that was created with Artifex itself. If you would like to know more about the model\\narchitecture or capapilities, or what the training process looked like, check out\\nthe \",[\"$\",\"a\",null,{\"href\":\"https://huggingface.co/tanaos/tanaos-sentiment-analysis-v1\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":\"model's Hugging Face page\"}],\".\"]}]\n2c:[\"$\",\"h2\",null,{\"children\":"])</script><script>self.__next_f.push([1,"\"Conclusion\"}]\n2d:[\"$\",\"p\",null,{\"children\":\"In this post, we saw how to use Artifex to perform local sentiment analysis using a small,\\ntask-specific LLM that runs entirely on our CPU. This approach allows us to analyze user feedback\\nwhile preserving their privacy.\"}]\n2e:[\"$\",\"p\",null,{\"children\":[\"Artifex provides many other task-specific models that can be used for various NLP tasks, such as\\ntext classification, named entity recognition, guardrailing, and more. Feel free to explore the\\n\",[\"$\",\"a\",null,{\"href\":\"https://github.com/tanaos/artifex\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":\"Artifex GitHub repository\"}],\" and the\\n\",[\"$\",\"a\",null,{\"href\":\"https://docs.tanaos.com/artifex/\",\"target\":\"_blank\",\"rel\":\"noreferrer\",\"children\":\"Artifex docs\"}],\" for more information.\"]}]\n"])</script><script>self.__next_f.push([1,"d:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n9:null\n"])</script><script>self.__next_f.push([1,"b:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Analyze your users' sentiment without sending their data to third-party servers | Tanaos Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"keywords\",\"content\":\"task-specific LLM,offline NLP,text classification,local sentiment analysis,sentiment classification,privacy-first ML\"}],[\"$\",\"link\",\"2\",{\"rel\":\"canonical\",\"href\":\"undefined/blog/analyze-user-sentiment-locally/\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:title\",\"content\":\"Analyze your users' sentiment without sending their data to third-party servers\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:url\",\"content\":\"undefined/blog/analyze-user-sentiment-locally/\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:image\",\"content\":\"https://tanaos.com/images/blog/sentiment-analysis.png\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:image:alt\",\"content\":\"Analyze your users' sentiment without sending their data to third-party servers\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"10\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:title\",\"content\":\"Analyze your users' sentiment without sending their data to third-party servers\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:image\",\"content\":\"https://tanaos.com/images/blog/sentiment-analysis.png\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"10:\"$b:metadata\"\n"])</script></body></html>