1:"$Sreact.fragment"
2:I[58665,["87","static/chunks/0e762574-952dd08a96c1245d.js","711","static/chunks/8e1d74a4-b11957bef1dd4fbf.js","754","static/chunks/754-c636fd1d5677d3bc.js","356","static/chunks/356-a1921fb11ab00663.js","177","static/chunks/app/layout-9f07bcd6202fe4db.js"],"Navbar"]
3:I[9766,[],""]
4:I[98924,[],""]
5:I[52619,["87","static/chunks/0e762574-952dd08a96c1245d.js","754","static/chunks/754-c636fd1d5677d3bc.js","883","static/chunks/883-2b291bba2a595a03.js","356","static/chunks/356-a1921fb11ab00663.js","953","static/chunks/app/blog/%5Bslug%5D/page-e9f86361092ee138.js"],""]
6:I[41402,["87","static/chunks/0e762574-952dd08a96c1245d.js","711","static/chunks/8e1d74a4-b11957bef1dd4fbf.js","754","static/chunks/754-c636fd1d5677d3bc.js","356","static/chunks/356-a1921fb11ab00663.js","177","static/chunks/app/layout-9f07bcd6202fe4db.js"],""]
b:I[57150,[],""]
:HL["/_next/static/media/0484562807a97172-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/8888a3826f4a3af4-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/eafabf029ad39a43-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/330df8a60483a06e.css","style"]
:HL["/_next/static/css/5388290d976a8ef2.css","style"]
:HL["/_next/static/css/c334275b0572c852.css","style"]
:HL["/_next/static/css/0fb36d5ac05ca721.css","style"]
:HL["/_next/static/css/5d643ef3b3193cbd.css","style"]
0:{"P":null,"b":"lfUVL60zJJ9RIYhzKHv2X","p":"","c":["","blog","analyze-user-sentiment-locally",""],"i":false,"f":[[["",{"children":["blog",{"children":[["slug","analyze-user-sentiment-locally","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/330df8a60483a06e.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/5388290d976a8ef2.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/_next/static/css/c334275b0572c852.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__className_cc80f9","children":[["$","div",null,{"className":"app","children":[["$","$L2",null,{}],["$","main",null,{"className":"content","children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","footer",null,{"className":"Footer_footer__Ir1kR","children":["$","div",null,{"className":"Footer_footer-inner__mvqEE","children":[["$","div",null,{"className":"Footer_footer-top__kBSno","children":[["$","div",null,{"className":"Footer_footer-nav__NeXbd","children":[["$","$L5",null,{"href":"/","children":"Home"}],["$","$L5",null,{"href":"/blog/","children":"Blog"}],["$","a",null,{"href":"https://platform.tanaos.com","rel":"noreferrer","target":"_blank","children":"Platform"}],["$","a",null,{"href":"/models/ticket-classification/","children":"Ticket Classification"}],["$","a",null,{"href":"/models/contact-form-spam-filter/","children":"Contact Form Spam Filter"}],["$","a",null,{"href":"/models/email-intent-detection/","children":"Email Intent Detection"}]]}],["$","div",null,{"className":"Footer_footer-social__kWIvl","children":[["$","a",null,{"href":"https://github.com/tanaos","rel":"noreferrer","target":"_blank","aria-label":"GitHub","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 16 16","children":["$undefined",[["$","path","0",{"d":"M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.01 8.01 0 0 0 16 8c0-4.42-3.58-8-8-8","children":[]}]]],"className":"$undefined","style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}]}],["$","a",null,{"href":"https://huggingface.co/tanaos","rel":"noreferrer","target":"_blank","aria-label":"Hugging Face","children":"ðŸ¤—"}]]}]]}],["$","div",null,{"className":"Footer_footer-divider__t_9Q_"}],["$","div",null,{"className":"Footer_footer-bottom__3DnO7","children":["$","span",null,{"children":["Â© ",2026," Tanaos. All rights reserved."]}]}]]}]}]]}],["$","$L6",null,{"id":"ga-init","strategy":"afterInteractive","children":"\n                        window.dataLayer = window.dataLayer || [];\n                        function gtag(){dataLayer.push(arguments);}\n                        gtag('js', new Date());\n                        gtag('config', 'G-HRQ77GT2C8');\n                    "}]]}]}]]}],{"children":["blog","$L7",{"children":[["slug","analyze-user-sentiment-locally","d"],"$L8",{"children":["__PAGE__","$L9",{},null,false]},null,false]},null,false]},null,false],"$La",false]],"m":"$undefined","G":["$b",[]],"s":false,"S":true}
d:I[24431,[],"OutletBoundary"]
f:I[15278,[],"AsyncMetadataOutlet"]
11:I[24431,[],"ViewportBoundary"]
13:I[24431,[],"MetadataBoundary"]
14:"$Sreact.suspense"
7:["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
8:["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
9:["$","$1","c",{"children":["$Lc",[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/0fb36d5ac05ca721.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/5d643ef3b3193cbd.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$Ld",null,{"children":["$Le",["$","$Lf",null,{"promise":"$@10"}]]}]]}]
a:["$","$1","h",{"children":[null,[["$","$L11",null,{"children":"$L12"}],["$","meta",null,{"name":"next-size-adjust","content":""}]],["$","$L13",null,{"children":["$","div",null,{"hidden":true,"children":["$","$14",null,{"fallback":null,"children":"$L15"}]}]}]]}]
16:I[81356,["87","static/chunks/0e762574-952dd08a96c1245d.js","754","static/chunks/754-c636fd1d5677d3bc.js","883","static/chunks/883-2b291bba2a595a03.js","356","static/chunks/356-a1921fb11ab00663.js","953","static/chunks/app/blog/%5Bslug%5D/page-e9f86361092ee138.js"],"Image"]
17:I[50270,["87","static/chunks/0e762574-952dd08a96c1245d.js","754","static/chunks/754-c636fd1d5677d3bc.js","883","static/chunks/883-2b291bba2a595a03.js","356","static/chunks/356-a1921fb11ab00663.js","953","static/chunks/app/blog/%5Bslug%5D/page-e9f86361092ee138.js"],"CodeSnippet"]
18:T444,import csv
from openai import OpenAI


client = OpenAI(api_key="YOUR_API_KEY")

def analyze_sentiment(comment):
  prompt = f"Analyze the sentiment of the following comment: '{comment}'. Return a single word: 'very_positive', 'positive', 'neutral', 'negative' or 'very_negative'."

  response = client.chat.completions.create(
      model="gpt-4.1",
      messages=[
          {"role": "system", "content": "You are a sentiment analysis assistant."},
          {"role": "user", "content": prompt}
      ]
  )
  sentiment = response.choices[0].message.content.strip().lower()
  return sentiment

with open("user_comments.csv", mode="r", newline="", encoding="utf-8") as infile, open("user_comments_with_sentiment.csv", mode="w", newline="", encoding="utf-8") as outfile:
  reader = csv.DictReader(infile)
  fieldnames = reader.fieldnames + ["sentiment"]
  writer = csv.DictWriter(outfile, fieldnames=fieldnames)
  writer.writeheader()
  for row in reader:
      comment = row["comment"]
      sentiment = analyze_sentiment(comment)
      row["sentiment"] = sentiment
      writer.writerow(row)
c:["$","article",null,{"className":"BlogPage_article__fv9gc","children":[["$","$L5",null,{"href":"/blog/","className":"BlogPage_back-link__G6xqk","children":[["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 16 16","children":["$undefined",[["$","path","0",{"fillRule":"evenodd","d":"M15 8a.5.5 0 0 0-.5-.5H2.707l3.147-3.146a.5.5 0 1 0-.708-.708l-4 4a.5.5 0 0 0 0 .708l4 4a.5.5 0 0 0 .708-.708L2.707 8.5H14.5A.5.5 0 0 0 15 8","children":[]}]]],"className":"$undefined","style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}]," Back to blog"]}],["$","h1",null,{"className":"mt-4","children":"Analyze your users' sentiment without sending their data to third-party servers"}],["$","p",null,{"className":"BlogPage_subtitle__wqaGw","children":"Perform local sentiment analysis using a small, task-specific LLM that runs entirely on your CPU without making it go BRRR."}],["$","p",null,{"className":"BlogPage_date__VyN7U","children":"December 16, 2025"}],["$","$L16",null,{"className":"mt-5 mb-5 BlogPage_post-image__Du0zR","src":"/images/blog/sentiment-analysis.png","alt":"Analyze your users' sentiment without sending their data to third-party servers","width":1200,"height":630,"unoptimized":true}],[["$","p",null,{"children":["As we noted in our previous ",["$","$L5",null,{"href":"/blog/offline-nlp/","children":"post on offline NLP"}],",\nmany developers have gotten used to throwing an LLM API, or at least a general-purpose LLM, at\nwhatever language-related problem they are facing. While this is probably the most practical choice,\nor at least the one that comes to mind most easily, it is not necessarily to best one in terms\nof ",["$","strong",null,{"children":"costs, data privacy and speed"}],"."]}],"\n",["$","p",null,{"children":"Let's see why."}],"\n",["$","h2",null,{"children":"Our objective"}],"\n",["$","p",null,{"children":"Let's say we have a tech product that's been on the market for a few months. Our social media pages\nare quite active, and we get lots of user feedback."}],"\n",["$","p",null,{"children":["As it turns out, most users love our product, some users find it ",["$","em",null,{"children":"meh"}]," and a handful of them\nhate it. Or at least that's what our gut feeling is, based on comments to our social media posts\nand direct messages we receive. If we want to have a more precise idea of what users think, however,\n",["$","strong",null,{"children":"we need metrics"}],"."]}],"\n",["$","h2",null,{"children":"The classic approach"}],"\n",["$","p",null,{"children":"That's easy enough. We will just find a way to download all user comments and DMs, put them in a\nCSV file and feed it to the OpenAI API."}],"\n",["$","p",null,{"children":"The CSV file might look something like this."}],"\n",["$","$L17",null,{"language":"csv","code":"id,time,username,comment\n1,2025-12-01 12:34:56,user1234,\"I love this product! It has changed my life.\"\n2,2025-12-02 14:23:45,user5678,\"This product is okay, but it could be better.\"\n3,2025-12-03 16:12:34,user9101,\"I hate it! It's the worst thing I've ever used.\"\n...\n1000,2025-12-15 18:45:23,user4321,\"Not bad, but not great either.\"\n"}],"\n",["$","p",null,{"children":["$","em",null,{"children":"Classic user9101. Always so dramatic."}]}],"\n",["$","p",null,{"children":"Now let's write a simple script that reads the CSV file, sends each comment to the OpenAI API\nfor sentiment analysis, and stores the results in a new CSV file."}],"\n",["$","$L17",null,{"language":"python","code":"$18"}],"\n","$L19","\n","$L1a","\n","$L1b","\n","$L1c","\n","$L1d","\n","$L1e","\n","$L1f","\n","$L20","\n","$L21","\n","$L22","\n","$L23","\n","$L24","\n","$L25","\n","$L26","\n","$L27","\n","$L28","\n","$L29","\n","$L2a","\n","$L2b","\n","$L2c","\n","$L2d","\n","$L2e","\n","$L2f","\n","$L30","\n","$L31","\n","$L32"]]}]
19:["$","p",null,{"children":"The result looks like this."}]
1a:["$","$L17",null,{"language":"csv","code":"id,time,username,comment,sentiment\n1,2025-12-01 12:34:56,user1234,\"I love this product! It has changed my life.\",very_positive\n2,2025-12-02 14:23:45,user5678,\"This product is okay, but it could be better.\",neutral\n3,2025-12-03 16:12:34,user9101,\"I hate it! It's the worst thing I've ever used.\",very_negative\n...\n1000,2025-12-15 18:45:23,user4321,\"Not bad, but not great either.\",neutral\n"}]
1b:["$","p",null,{"children":"The result is what we wanted, the process was relatively fast and, unless our CSV dataset had a billion rows, the\ncost was negligible."}]
1c:["$","h2",null,{"children":"The privacy problem"}]
1d:["$","p",null,{"children":["If it was so easy, then why did we even bother writing this tutorial? Well, if you think about it, each one of\nthose reviews was sent to a ",["$","strong",null,{"children":"third-party server"}],", together with the ",["$","strong",null,{"children":"username of the person who wrote it"}],"\nand the ",["$","strong",null,{"children":"timestamp"}]," at which it was written. Even if we wrote the script in such a way that OpenAI API only\nreceives the actual reviews (and not username and timestamp), chances are that some of the reviews themselves\ncontain ",["$","strong",null,{"children":"personally identifiable information"}]," (PII), like names, locations, email addresses, phone numbers,\netc."]}]
1e:["$","p",null,{"children":["Would our users be happy if they found out that, unbeknownst to them, their reviews and messages were sent to\na ",["$","strong",null,{"children":"third-party server for analysis"}],"? Probably not. Is this ",["$","strong",null,{"children":"GDPR-compliant"}],"? Certainly not. Could we technically\n",["$","strong",null,{"children":"face a lawsuit"}],"? I am afraid so."]}]
1f:["$","h2",null,{"children":"A better approach: local sentiment analysis"}]
20:["$","p",null,{"children":["We could, in theory, bypass the privacy issue by hosting our own instance of an open-source general-purpose LLM,\nlike Llama, DeepSeek or Mistral. But do we really want to host a ",["$","strong",null,{"children":"multi-billion parameter model"}]," on our own servers,\n",["$","strong",null,{"children":"just to analyze product reviews"}],"? Not really."]}]
21:["$","p",null,{"children":["The better approach is to use a ",["$","strong",null,{"children":"small, task-specific model"}]," that can run entirely on our local device, without\nsending any data to third-party servers or requiring GPU acceleration. But where do we find a small model that can run\nlocally? Do we really have to look for one on Hugging Face and read its docs to figure out how to use it? We have\nbetter plans for the weekend."]}]
22:["$","p",null,{"children":["This is where ",["$","$L5",null,{"href":"https://github.com/tanaos/artifex","children":"Artifex"}]," comes in. Artifex is a Python library that\nprovides easy access to a variety of small, task-specific LLMs that run entirely on your CPU, as well as the\npossibility to fine-tune them on your specific tasks. Our sentiment analysis task is standard enough that Artifex\nalready provides a ",["$","strong",null,{"children":"pre-trained model"}]," for it, without any need for fine-tuning."]}]
23:["$","p",null,{"children":"Let's see how to do it."}]
24:["$","h3",null,{"children":"The new script"}]
25:["$","p",null,{"children":"First of all, let's install Artifex."}]
26:["$","$L17",null,{"code":"pip install artifex"}]
27:["$","p",null,{"children":"Once that's done, let's rewrite our previous script using Artifex's sentiment analysis model."}]
28:["$","$L17",null,{"language":"python","code":"import csv\nfrom artifex import Artifex\n\nsentiment_analyzer = Artifex().sentiment_analysis\n\nwith open(\"user_comments.csv\", mode=\"r\", newline=\"\", encoding=\"utf-8\") as infile, open(\"user_comments_with_sentiment.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n  reader = csv.DictReader(infile)\n  fieldnames = reader.fieldnames + [\"sentiment\"]\n  writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n  writer.writeheader()\n  for row in reader:\n      comment = row[\"comment\"]\n      sentiment = sentiment_analyzer(comment)[0].label\n      row[\"sentiment\"] = sentiment\n      writer.writerow(row)\n"}]
29:["$","p",null,{"children":["What we did here is instantiate an Artifex object and use its ",["$","code",null,{"children":"sentiment_analysis"}]," method to\nanalyze each comment. We removed the ",["$","code",null,{"children":"analyze_sentiment"}]," function and all references to OpenAI API,\nsince we don't need it anymore. The rest of the script remains unchanged."]}]
2a:["$","p",null,{"children":["If you need more information on how to use Artifex or the sentiment analysis model specifically, please refer\nto the ",["$","a",null,{"href":"https://docs.tanaos.com/artifex/sentiment-analysis/train/","target":"_blank","rel":"noreferrer","children":"Artifex documentation"}],"."]}]
2b:["$","p",null,{"children":"The new script gives us the same result as before."}]
2c:["$","$L17",null,{"language":"csv","code":"id,time,username,comment,sentiment\n1,2025-12-01 12:34:56,user1234,\"I love this product! It has changed my life.\",very_positive\n2,2025-12-02 14:23:45,user5678,\"This product is okay, but it could be better.\",neutral\n3,2025-12-03 16:12:34,user9101,\"I hate it! It's the worst thing I've ever used.\",very_negative\n...\n1000,2025-12-15 18:45:23,user4321,\"Not bad, but not great either.\",neutral\n"}]
2d:["$","p",null,{"children":"Cost of running the new script was $0, speed was comparable to the previous version, and most\nimportantly, our users' data never leaves our device and we don't risk having to hire a lawyer."}]
2e:["$","h3",null,{"children":"The pre-trained model"}]
2f:["$","p",null,{"children":["The ",["$","code",null,{"children":"sentiment_analysis"}]," method we used in the script above employs a small, pre-trained language\nmodel that was created with Artifex itself. If you would like to know more about the model\narchitecture or capapilities, or what the training process looked like, check out\nthe ",["$","a",null,{"href":"https://huggingface.co/tanaos/tanaos-sentiment-analysis-v1","target":"_blank","rel":"noreferrer","children":"model's Hugging Face page"}],"."]}]
30:["$","h2",null,{"children":"Conclusion"}]
31:["$","p",null,{"children":"In this post, we saw how to use Artifex to perform local sentiment analysis using a small,\ntask-specific LLM that runs entirely on our CPU. This approach allows us to analyze user feedback\nwhile preserving their privacy."}]
32:["$","p",null,{"children":["Artifex provides many other task-specific models that can be used for various NLP tasks, such as\ntext classification, named entity recognition, guardrailing, and more. Feel free to explore the\n",["$","a",null,{"href":"https://github.com/tanaos/artifex","target":"_blank","rel":"noreferrer","children":"Artifex GitHub repository"}]," and the\n",["$","a",null,{"href":"https://docs.tanaos.com/artifex/","target":"_blank","rel":"noreferrer","children":"Artifex docs"}]," for more information."]}]
12:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
e:null
10:{"metadata":[["$","title","0",{"children":"Analyze your users' sentiment without sending their data to third-party servers | Tanaos Blog"}],["$","meta","1",{"name":"keywords","content":"task-specific LLM,offline NLP,text classification,local sentiment analysis,sentiment classification,privacy-first ML"}],["$","link","2",{"rel":"canonical","href":"undefined/blog/analyze-user-sentiment-locally/"}],["$","meta","3",{"property":"og:title","content":"Analyze your users' sentiment without sending their data to third-party servers"}],["$","meta","4",{"property":"og:url","content":"undefined/blog/analyze-user-sentiment-locally/"}],["$","meta","5",{"property":"og:image","content":"https://tanaos.com/images/blog/sentiment-analysis.png"}],["$","meta","6",{"property":"og:image:width","content":"1200"}],["$","meta","7",{"property":"og:image:height","content":"630"}],["$","meta","8",{"property":"og:image:alt","content":"Analyze your users' sentiment without sending their data to third-party servers"}],["$","meta","9",{"property":"og:type","content":"article"}],["$","meta","10",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","11",{"name":"twitter:title","content":"Analyze your users' sentiment without sending their data to third-party servers"}],["$","meta","12",{"name":"twitter:image","content":"https://tanaos.com/images/blog/sentiment-analysis.png"}]],"error":null,"digest":"$undefined"}
15:"$10:metadata"
