1:"$Sreact.fragment"
2:I[63488,["619","static/chunks/619-28045d4483afb7ae.js","177","static/chunks/app/layout-6684dbfe3c877ad1.js"],"Navbar"]
3:I[9766,[],""]
4:I[98924,[],""]
5:I[52619,["619","static/chunks/619-28045d4483afb7ae.js","356","static/chunks/356-a1921fb11ab00663.js","953","static/chunks/app/blog/%5Bslug%5D/page-fee087f1fd1a3786.js"],""]
6:I[41402,["619","static/chunks/619-28045d4483afb7ae.js","177","static/chunks/app/layout-6684dbfe3c877ad1.js"],""]
8:I[24431,[],"OutletBoundary"]
a:I[15278,[],"AsyncMetadataOutlet"]
c:I[24431,[],"ViewportBoundary"]
e:I[24431,[],"MetadataBoundary"]
f:"$Sreact.suspense"
11:I[57150,[],""]
:HL["/_next/static/media/0484562807a97172-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/8888a3826f4a3af4-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/eafabf029ad39a43-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/0473445cc75846a4.css","style"]
:HL["/_next/static/css/d6520f7d9dad7f09.css","style"]
:HL["/_next/static/css/c334275b0572c852.css","style"]
:HL["/_next/static/css/0733fdd18aa74344.css","style"]
0:{"P":null,"b":"JaHKo1uo54KFPX9696sEi","p":"","c":["","blog","task-specific-llms",""],"i":false,"f":[[["",{"children":["blog",{"children":[["slug","task-specific-llms","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/0473445cc75846a4.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/d6520f7d9dad7f09.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/_next/static/css/c334275b0572c852.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__className_cc80f9","children":[["$","div",null,{"className":"app","children":[["$","$L2",null,{}],["$","main",null,{"className":"content","children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","div",null,{"className":"row Footer_footer__Ir1kR m-0 align-items-center","children":[["$","div",null,{"className":"col-12 col-md-4 m-0 p-0 text-start","children":["Copyright Â© ",2025," Tanaos"]}],["$","div",null,{"className":"col-md-4 text-md-center d-none d-md-block","children":"Tanaos"}],["$","div",null,{"className":"col-12 col-md-4 text-md-end mt-4 mt-md-0 Footer_footer-links__9Skqm m-0 p-0","children":[["$","$L5",null,{"href":"/","children":"Home"}],["$","$L5",null,{"href":"/blog/","children":"Blog"}],["$","a",null,{"href":"https://docs.tanaos.com/artifex/","rel":"noreferrer","target":"_blank","children":"Docs"}],["$","a",null,{"href":"https://platform.tanaos.com","rel":"noreferrer","target":"_blank","children":"Platform"}]]}]]}]]}],["$","$L6",null,{"id":"ga-init","strategy":"afterInteractive","children":"\n                        window.dataLayer = window.dataLayer || [];\n                        function gtag(){dataLayer.push(arguments);}\n                        gtag('js', new Date());\n                        gtag('config', 'G-HRQ77GT2C8');\n                    "}]]}]}]]}],{"children":["blog",["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","task-specific-llms","d"],["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L7",[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/0733fdd18aa74344.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$L8",null,{"children":["$L9",["$","$La",null,{"promise":"$@b"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,[["$","$Lc",null,{"children":"$Ld"}],["$","meta",null,{"name":"next-size-adjust","content":""}]],["$","$Le",null,{"children":["$","div",null,{"hidden":true,"children":["$","$f",null,{"fallback":null,"children":"$L10"}]}]}]]}],false]],"m":"$undefined","G":["$11",[]],"s":false,"S":true}
12:I[81356,["619","static/chunks/619-28045d4483afb7ae.js","356","static/chunks/356-a1921fb11ab00663.js","953","static/chunks/app/blog/%5Bslug%5D/page-fee087f1fd1a3786.js"],"Image"]
7:["$","article",null,{"className":"BlogPage_article__fv9gc","children":[["$","$L5",null,{"href":"/blog/","className":"BlogPage_back-link__G6xqk","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 16 16","width":"1em","height":"1em","fill":"currentColor","className":"bi bi-arrow-left","children":[null,["$","path",null,{"fillRule":"evenodd","d":"M15 8a.5.5 0 0 0-.5-.5H2.707l3.147-3.146a.5.5 0 1 0-.708-.708l-4 4a.5.5 0 0 0 0 .708l4 4a.5.5 0 0 0 .708-.708L2.707 8.5H14.5A.5.5 0 0 0 15 8"}]]}]," Back to blog"]}],["$","h1",null,{"className":"mt-4","children":"Working on text classification? Use a task-specific LLM."}],["$","p",null,{"className":"BlogPage_subtitle__wqaGw","children":"Here is why you should stop using general-purpose LLMs for narrow tasks like text classification."}],["$","p",null,{"className":"BlogPage_date__VyN7U","children":"September 15, 2025"}],["$","$L12",null,{"className":"mt-5 mb-5 BlogPage_post-image__Du0zR","src":"/images/blog/task-specific-llm-for-text-classification.png","alt":"Working on text classification? Use a task-specific LLM.","width":1200,"height":630,"unoptimized":true}],[["$","div",null,{"className":"TLDRBox_tldr-box__UF_9W","children":[["$","h3",null,{"className":"TLDRBox_tldr-title__YbjzN","children":"TL;DR"}],["$","p",null,{"children":["When working on narrow, well-defined text classification tasks, general-purpose LLMs are typically overkill,\noverpriced and underperforming. Task-specific LLMs are smaller, cheaper (often free) to run and perform\nbetter on these tasks. Our ",["$","a",null,{"href":"https://github.com/tanaos/artifex","rel":"noreferrer","target":"_blank","children":["\nArtifex Python library ",["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 16 16","width":"1em","height":"1em","fill":"currentColor","className":"bi bi-box-arrow-up-right","children":[null,["$","path",null,{"fillRule":"evenodd","d":"M8.636 3.5a.5.5 0 0 0-.5-.5H1.5A1.5 1.5 0 0 0 0 4.5v10A1.5 1.5 0 0 0 1.5 16h10a1.5 1.5 0 0 0 1.5-1.5V7.864a.5.5 0 0 0-1 0V14.5a.5.5 0 0 1-.5.5h-10a.5.5 0 0 1-.5-.5v-10a.5.5 0 0 1 .5-.5h6.636a.5.5 0 0 0 .5-.5"}],["$","path",null,{"fillRule":"evenodd","d":"M16 .5a.5.5 0 0 0-.5-.5h-5a.5.5 0 0 0 0 1h3.793L6.146 9.146a.5.5 0 1 0 .708.708L15 1.707V5.5a.5.5 0 0 0 1 0z"}]]}],"\n"]}]," makes it easy to create and use task-specific LLMs\nwithout the need for any training data, so you can reduce the number of paid API calls to third-party\nLLM APIs."]}]]}],"\n",["$","p",null,{"children":"General-purpose LLMs are trained to be versatile across as wide a range of tasks as possible. They\nhandle themselves well in scenarios extending from code generation to creative writing. While this is very quickly\nturning them into an irreplaceable tool for many, it also means that they come with two main limitations:"}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"Cost"}],": as their very name suggests, LLMs are ",["$","em",null,{"children":"extremely large"}],". This means that they are expensive to run, and\ntheir use requires either specialized hardware, or access to a paid third-party API."]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Non-specificity"}],": because they are trained to be general-purpose, LLMs are not particularly good at\ntasks that require domain knowledge, or being trained on a specific dataset."]}],"\n"]}],"\n",["$","p",null,{"children":["In practice, this means that, when working on many narrow, well-defined tasks, general-purpose LLMs are often not\njust ",["$","strong",null,{"children":"overkill"}],", but also ",["$","strong",null,{"children":"underperforming"}],"."]}],"\n",["$","h2",null,{"children":"Text classification"}],"\n",["$","p",null,{"children":["Text classification is a prime example of this. While their formulation and objective are straightforward, many\ntext classification tasks such as ","$L13",", ","$L14"," or ","$L15","\nrequire understanding of the specific domain they are applied to, which LLMs can only obtain through ","$L16","."]}],"\n","$L17","\n","$L18","\n","$L19","\n","$L1a","\n","$L1b","\n","$L1c","\n","$L1d","\n","$L1e","\n","$L1f","\n","$L20","\n","$L21"]]}]
13:["$","strong",null,{"children":"topic categorization"}]
14:["$","strong",null,{"children":"intent classification"}]
15:["$","strong",null,{"children":"safety filtering"}]
16:["$","strong",null,{"children":"fine-tuning\non a relevant dataset"}]
17:["$","p",null,{"children":["Think, for instance, of a ",["$","strong",null,{"children":"safety filtering"}]," task, where the goal is to flag text that contains unwanted content\nas ",["$","em",null,{"children":"unsafe"}],". Since the definition of ",["$","em",null,{"children":"unwanted content"}]," really depends on the user's requirements, the only way\nto get a general-purpose LLM to perform well on this task is through thorough and ",["$","strong",null,{"children":"meticulous prompt engineering"}],".\nEven then, the results are often subpar, and the cost of running a general-purpose LLM for this relatively simple\ntask is non-trivial (especially at scale)."]}]
18:["$","p",null,{"children":["The same applies to a number of other text classification tasks, such as ",["$","strong",null,{"children":"intent classification"}],", where the LLM\nneeds to be provided with a list of possible intents and examples for each, ",["$","strong",null,{"children":"slot filling"}],", where the LLM needs\nto be told what slots to fill and how, and so on."]}]
19:["$","h2",null,{"children":"Task-specific LLMs"}]
1a:["$","p",null,{"children":["Task-specific LLMs are smaller, more focused LLMs that are trained to perform very well on a specific task, and not\nnecessarily on anything else. Due to their smaller size, they are ",["$","strong",null,{"children":"much cheaper to run"}]," than general-purpose LLMs,\nand they can be deployed on more modest hardware."]}]
1b:["$","p",null,{"children":["More importantly, task-specific LLMs are ",["$","strong",null,{"children":"trained on datasets that are relevant to the task at hand"}],". This means\nthat they can leverage domain knowledge and perform much better than general-purpose LLMs on narrow tasks.\nFor instance, a task-specific LLM for ",["$","strong",null,{"children":"safety filtering"}]," would be trained on a dataset of safe and unsafe\nmessages, as per the user's definition of safety, and would learn to identify patterns and features that are\nindicative of unwanted content."]}]
1c:["$","h2",null,{"children":"How Tanaos can help"}]
1d:["$","p",null,{"children":["Our ",["$","a",null,{"href":"https://github.com/tanaos/artifex","rel":"noreferrer","target":"_blank","children":"Artifex Python library"}]," provides\na simple and efficient way to create and use small-sized, task-specific LLMs for text classification tasks.\nMost importantly, Artifex allows you to create task-specific LLMs ",["$","strong",null,{"children":"without the need for any training data"}],".\nYou simply describe how the model should behave, and it will be trained on synthetic data generated\nfor that purpose."]}]
1e:["$","p",null,{"children":["The models created with Artifex are so lightweight that they can ",["$","strong",null,{"children":"run locally or on small servers\nwithout a GPU"}],", offloading simple tasks and reducing reliance on third-party LLM APIs."]}]
1f:["$","h2",null,{"children":"Give it a try"}]
20:["$","p",null,{"children":"Artifex is free and open-source. Check it out on GitHub!"}]
21:["$","a",null,{"className":"btn btn-primary","href":"https://github.com/tanaos/artifex","target":"_blank","rel":"noreferrer","children":["See Artifex on GitHub ",["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 16 16","width":"1em","height":"1em","fill":"currentColor","className":"bi bi-github ms-2","children":[null,["$","path",null,{"d":"M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.01 8.01 0 0 0 16 8c0-4.42-3.58-8-8-8"}]]}]]}]
d:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
9:null
b:{"metadata":[["$","title","0",{"children":"Working on text classification? Use a task-specific LLM. | Tanaos Blog"}],["$","meta","1",{"name":"keywords","content":"task-specific LLM,AI,text classification,without training data,NLP,machine learning"}],["$","link","2",{"rel":"canonical","href":"undefined/blog/task-specific-llms/"}],["$","meta","3",{"property":"og:title","content":"Working on text classification? Use a task-specific LLM."}],["$","meta","4",{"property":"og:url","content":"undefined/blog/task-specific-llms/"}],["$","meta","5",{"property":"og:image","content":"https://tanaos.com/images/blog/task-specific-llm-for-text-classification.png"}],["$","meta","6",{"property":"og:image:width","content":"1200"}],["$","meta","7",{"property":"og:image:height","content":"630"}],["$","meta","8",{"property":"og:image:alt","content":"Working on text classification? Use a task-specific LLM."}],["$","meta","9",{"property":"og:type","content":"article"}],["$","meta","10",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","11",{"name":"twitter:title","content":"Working on text classification? Use a task-specific LLM."}],["$","meta","12",{"name":"twitter:image","content":"https://tanaos.com/images/blog/task-specific-llm-for-text-classification.png"}]],"error":null,"digest":"$undefined"}
10:"$b:metadata"
